# MasterThesisCodeSummarization
This is part of my master thesis with title "Transformer-based source code summarization". Specifically, an ensembling learning-based approach is followed, with stacking on PLBart and GraphCodeBERT. To train and test the models, run the respective notebooks on Google Colab or your device. CodeBERT's repository needs to be forked and CodeBERT/GraphCodeBERT/translation/run.py should be replaced by our run.py file. The used dataset is from CodeSearchNet.
